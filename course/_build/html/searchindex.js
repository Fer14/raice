Search.setIndex({"alltitles": {"A2C (Advantage Actor-Critic)": [[5, null]], "A2C Algorithm": [[5, "a2c-algorithm"]], "Actor-Critic Overview": [[5, "actor-critic-overview"]], "Actual training": [[2, "actual-training"], [3, "actual-training"], [4, "actual-training"], [5, "actual-training"]], "Advantage Function": [[5, "advantage-function"]], "Algorithms": [[1, "algorithms"]], "Coding A2C": [[5, "coding-a2c"]], "Coding Deep Q-Network": [[3, "coding-deep-q-network"]], "Coding Policy Gradients": [[2, "coding-policy-gradients"]], "Coding SARSA": [[4, "coding-sarsa"]], "Course Structure:": [[0, "course-structure"]], "Epsilon-Greedy Exploration": [[3, "epsilon-greedy-exploration"]], "Epsilon-Greedy Exploration in SARSA": [[4, "epsilon-greedy-exploration-in-sarsa"]], "Exploration vs. Exploitation": [[1, "exploration-vs-exploitation"]], "Key Components of A2C": [[5, "key-components-of-a2c"]], "On-Policy vs. Off-Policy Learning": [[1, "on-policy-vs-off-policy-learning"]], "Policy gradients (Reinforce)": [[2, null]], "Prerequisites:": [[0, "prerequisites"]], "Q-Learning": [[3, null]], "RAICE: An Example Scenario": [[1, "raice-an-example-scenario"]], "Reinforcement Learning": [[1, null]], "Replay Memory": [[3, "replay-memory"]], "SARSA (State-Action-Reward-State-Action)": [[4, null]], "Target network": [[3, "target-network"]], "Temporal Difference Learning in SARSA": [[4, "temporal-difference-learning-in-sarsa"]], "Temporal difference learning": [[3, "temporal-difference-learning"]], "The A2C Process": [[5, "the-a2c-process"]], "The Actions a": [[1, "the-actions-a"]], "The Advantage Function": [[5, "the-advantage-function"]], "The Agent": [[1, "the-agent"]], "The Environment": [[1, "the-environment"]], "The Policy Gradient Process": [[2, "the-policy-gradient-process"]], "The Q-Learning Process": [[3, "the-q-learning-process"]], "The Q-Value Function": [[3, "the-q-value-function"]], "The Q-Value Function in SARSA": [[4, "the-q-value-function-in-sarsa"]], "The Reward r": [[1, "the-reward-r"]], "The SARSA Process": [[4, "the-sarsa-process"]], "The State s": [[1, "the-state-s"]], "The objective function": [[2, "the-objective-function"]], "Training the Agent": [[1, "training-the-agent"]], "Welcome to RAICE!": [[0, null]], "What You Will Learn:": [[0, "what-you-will-learn"]], "What is Reinforcement Learning?": [[1, "what-is-reinforcement-learning"]], "Why Use Advantage?": [[5, "why-use-advantage"]]}, "docnames": ["00_introduction", "01_reinforcement_learning", "02_policy_gradients", "03_dqn", "04_sarsa", "05_a2c", "intro"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["00_introduction.ipynb", "01_reinforcement_learning.ipynb", "02_policy_gradients.ipynb", "03_dqn.ipynb", "04_sarsa.ipynb", "05_a2c.ipynb", "intro.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 2, 3, 4, 5], "0": [1, 2, 3, 4, 5], "000": 3, "1": [1, 2, 3, 4, 5], "10": [1, 2, 3, 4, 5], "120": 1, "15": 1, "2": [1, 2, 3, 4, 5], "200": 1, "2r_": 1, "3": [1, 2], "30": 1, "360": 1, "400": 1, "45": 1, "5": 1, "50": 2, "500": 1, "6": [2, 3, 4, 5], "7": 1, "700": 1, "8": 1, "90": 1, "A": [0, 1, 2, 5], "As": 1, "At": 5, "But": [0, 1], "By": [1, 2, 3], "For": [0, 1, 2, 3, 4], "If": [1, 2, 4], "In": [0, 1, 2, 3, 4, 5], "It": [1, 3, 5], "OF": [2, 3, 4, 5], "Or": 2, "THE": [2, 3, 4, 5], "Thats": 1, "The": 0, "There": [0, 1], "These": [1, 2, 6], "To": [1, 2, 3], "With": [3, 4], "__init__": [2, 3, 4, 5], "_\u03c4": 2, "_\u03c4p": 2, "a2car": 5, "a2crac": 5, "a_": 1, "a_0": 2, "a_1": 2, "a_t": [1, 2], "aa": [3, 4, 5], "abl": 0, "about": 1, "ac": 5, "acceler": 5, "accompani": 0, "accord": [2, 4, 5], "account": 2, "accumul": 2, "achiev": [0, 1], "act_epsilon_greedi": [3, 4], "action": [0, 2, 3, 5], "action_train": [2, 3, 4, 5], "actor": 1, "actor_loss": 5, "actorcrit": 5, "actual": 1, "ad": 3, "adapt": 0, "address": 3, "adjust": [0, 1, 2, 3, 5], "after": [2, 3, 4, 5], "again": 4, "agent": [0, 2, 3, 4, 5], "aggress": 0, "ai": [0, 1], "aim": [1, 3, 4], "algorithm": [0, 2, 3, 4], "all": [1, 2, 3, 4], "allow": [0, 1, 2, 3, 5], "along": 2, "alpha": 2, "alreadi": [0, 1], "also": [0, 1, 2, 4], "altern": 1, "alwai": 1, "among": 1, "an": [0, 2, 3, 4, 5], "angl": [1, 2, 3, 4, 5], "ani": [1, 3], "anoth": 1, "append": [2, 5], "appli": [0, 2], "applic": 0, "approach": [1, 3], "approxim": 5, "ar": [0, 1, 2, 3, 4, 5, 6], "arbitrarili": [3, 4], "argmax": [3, 4], "arrai": [2, 3, 4], "artifici": 0, "ascent": 2, "aspect": 1, "asphalt": 1, "assign": 1, "associ": 1, "assum": 3, "asynchron": 5, "atmospher": 1, "augment": 1, "averag": 5, "avoid": [0, 1], "background": 1, "backpropag": 4, "backward": [2, 3, 4, 5], "bahrain": 1, "bahrain2": 1, "balanc": [0, 1, 3, 4], "ball": 1, "base": [0, 1, 2, 3, 4, 5], "baselin": 5, "basic": [0, 2], "becaus": 1, "becom": 3, "befor": 1, "behavior": [0, 1], "behind": 5, "being": 1, "bellman": 3, "below": 3, "best": [0, 1, 3, 4], "better": [0, 1, 5], "between": [0, 1, 3, 4, 5], "black": 1, "blue": 1, "bonu": 5, "bootstrap": [3, 5], "both": [0, 1, 3, 5], "boundari": 0, "break": [0, 3], "buffer": 3, "c1": 5, "c1critic": 5, "c2": 5, "c2entropi": 5, "calcul": [4, 5], "can": [0, 1, 2, 3], "captur": [1, 5], "car": [0, 1, 2, 3, 4, 5], "carlo": [2, 3], "carri": 1, "case": [0, 1, 2], "categor": [2, 5], "cdot": 2, "center": 1, "central": 3, "certain": 1, "chang": 3, "chapter": [0, 3], "choic": 1, "choos": [1, 3, 4, 5], "chosen": 5, "class": [2, 3, 4, 5], "clear": [0, 1], "clip_grad_norm_": 3, "close": 4, "co": 1, "code": 0, "collect": [2, 3], "collid": 0, "color": 1, "column": 1, "combin": [0, 1, 3, 5], "come": 1, "comfort": 0, "common": 3, "compar": [1, 5], "compet": 0, "competit": 0, "complet": [0, 2], "complex": [0, 1], "complic": 1, "compon": 3, "comput": [1, 2, 3, 4, 5], "concept": [0, 1, 5], "conceptu": 0, "confid": 5, "configur": 1, "consecut": 3, "consid": 1, "consist": [1, 5], "context": 1, "contrast": 3, "contribut": [2, 5], "control": [3, 4, 5], "converg": [2, 3, 4], "convers": 1, "copi": 3, "core": [0, 5], "corner": 1, "cornerston": 1, "correl": 3, "correspond": 1, "cort\u00e9": 6, "could": [1, 3, 5], "cours": [1, 6], "cover": [0, 1], "crash": 1, "creat": 1, "create_model": [2, 3, 4], "critic": 1, "critic_loss": 5, "critic_weight": 5, "crossov": 1, "crucial": 1, "cumul": [1, 3, 4, 5], "current": [1, 2, 3, 4, 5], "current_q_valu": [3, 4], "current_st": [2, 3, 4, 5], "d": 1, "data": 1, "debug": 0, "decai": [1, 3, 4], "decid": 5, "decis": [0, 1, 2], "decreas": 1, "deep": 0, "def": [1, 2, 3, 4, 5], "default": 1, "defin": [1, 2, 5], "degre": 1, "delv": [0, 1], "denot": 3, "depend": 1, "deriv": [2, 3], "descent": 2, "design": 1, "desir": 1, "detach": 5, "detail": [0, 3, 5], "detect": 1, "determin": [1, 3], "determinist": 1, "develop": 1, "devic": [2, 3, 4, 5], "differ": [0, 1, 5], "dilemma": 1, "dim": 5, "dine": 1, "dinner": 1, "direct": [1, 2], "directli": [0, 1, 2, 3, 5], "discount": [1, 2, 3, 4, 5], "discount_factor": [2, 3, 4, 5], "discourag": 1, "discov": 1, "discuss": [1, 2], "displai": 1, "distanc": 1, "distant": 2, "distribut": [1, 2, 5], "dive": [0, 3], "divers": 3, "do": 2, "doe": 3, "doesn": [1, 3], "done": [2, 3, 4, 5], "dot": 2, "down": [0, 1, 2, 3, 4, 5], "dqn": [1, 3], "draw": 1, "drive": [0, 1, 3, 4], "driver": 1, "dtype": [2, 3, 4], "dure": [1, 2, 3, 5], "dynam": [0, 1], "e": [0, 1, 3, 5], "e_\u03c0": 1, "each": [0, 1, 2, 3, 4, 5], "earli": [3, 5], "earlier": 2, "effect": [1, 3], "effici": [0, 1, 3], "either": 1, "element": 1, "elif": [2, 3, 4, 5], "els": [2, 3, 4, 5], "embark": 0, "emploi": 1, "enabl": 1, "encompass": 1, "encount": 2, "encourag": [1, 5], "end": [0, 2, 3, 4], "enjoy": 1, "ensur": 3, "entir": [1, 2], "entropi": 5, "entropy_loss": 5, "entropy_weight": 5, "environ": [0, 2, 3, 5], "episod": [2, 3, 4, 5], "episode_reward": [2, 3, 4, 5], "epsilon_decai": [3, 4], "equal": 3, "equat": [3, 4], "equip": 1, "equival": 2, "errat": 3, "error": [0, 1, 3, 4, 5], "especi": 3, "essenti": 1, "estim": [1, 2, 3, 5], "evalu": [1, 5], "even": 3, "everi": [1, 2, 3], "evolut": 1, "evolutionari": 0, "evolv": [0, 1], "exactli": 1, "exampl": 0, "excit": [0, 1], "execut": [2, 3, 4, 5], "exist": 1, "expect": [1, 2, 3, 4, 5], "experi": [0, 1, 2, 3], "explain": [0, 2], "explan": 0, "exploit": [0, 3, 4], "explor": [0, 5], "exploratori": 3, "express": [2, 3], "e\u03c4": 2, "f": 1, "f1": [0, 1], "face": 1, "fact": 2, "factor": [1, 2, 3, 4, 5], "fals": [2, 3, 4, 5], "familiar": [0, 1], "far": 3, "favor": 5, "favorit": 1, "feed": 1, "feedback": [0, 1, 3, 5], "fernando": 6, "fetch": 1, "fill": 1, "final": 1, "find": [0, 1], "fine": 1, "finish": 3, "finnish": 4, "first": [0, 2], "fit": 1, "five": 1, "fix": 3, "flexibl": 3, "float": 2, "float32": [2, 3, 4], "floattensor": 5, "fluctuat": 3, "focu": [0, 1, 5], "focus": [0, 1], "follow": [0, 1, 2, 3, 4], "font": 1, "food": 1, "form": [0, 3], "formal": [1, 2, 3], "formul": [1, 2], "formula": 3, "forward": [2, 5], "foundat": 1, "four": 1, "free": 1, "frequent": 3, "fresh": 1, "from": [0, 1, 2, 3, 4, 5], "from_numpi": 2, "front": 1, "frozen": 3, "function": [0, 1], "fundament": 0, "futur": [1, 2, 3, 4, 5], "future_return": 2, "g": [0, 1, 2], "g_t": 2, "gain": 0, "game": [0, 1], "gamma": 2, "gather": [1, 3, 4], "gener": [0, 1, 2], "genet": [0, 1], "get": [0, 4, 5], "get_data": [2, 3, 4, 5], "get_q": [3, 4], "give": 2, "given": [1, 2, 3, 5], "go": 0, "goal": [0, 1, 2, 5], "good": [0, 1, 5], "gradient": [0, 3, 5], "gradual": 3, "grasp": 0, "greater": 1, "greatli": 1, "green": 1, "grid": 1, "gridworld": 0, "gt": 3, "guarante": 1, "guid": [0, 1], "ha": [1, 4], "hand": [0, 1], "happen": 1, "have": [1, 2, 4], "heavili": 2, "help": [0, 1, 2, 3, 5], "here": [2, 3, 4, 5], "hidden_s": 5, "high": [1, 3], "higher": [2, 5], "highest": [3, 4], "highli": 5, "histor": 1, "hold": 1, "horizon": 2, "how": [0, 1, 2, 3, 4, 5], "howev": [1, 3, 4], "human": 1, "hybrid": 1, "hyperparamet": 5, "i": [0, 2, 3, 4, 5], "idea": [0, 3, 5], "imag": 1, "imagedraw": 1, "imagefont": 1, "imagin": 1, "immedi": [1, 2, 3, 4], "implement": [0, 5], "import": [1, 2, 3, 4, 5], "improv": [0, 1, 2, 3, 5], "includ": 1, "incorpor": [1, 5], "increas": [1, 2], "increment": 3, "independ": 1, "indic": [1, 5], "indirectli": 3, "inform": [1, 3], "initi": [2, 3, 4, 5], "input_s": 5, "insert": [2, 3, 4, 5], "instabl": 3, "instead": [1, 3, 5], "int": [1, 3, 4], "intellig": 0, "interact": [0, 1, 2, 3, 5], "intili": 2, "intiliaz": [3, 4], "intric": 1, "introduc": 3, "intuit": 0, "involv": [1, 2, 5], "ipython": 1, "irrelev": 1, "item": [2, 3, 4, 5], "iter": [1, 3], "its": [1, 2, 3, 5], "itself": 1, "j": 2, "journei": 0, "just": [1, 5], "k": 2, "keep": 1, "kei": [0, 1, 3, 4], "know": 1, "knowledg": [0, 3], "known": [0, 1, 2, 3, 5], "label": 1, "lack": 1, "lap": 0, "later": 2, "lead": [1, 2, 3, 5], "learn": [2, 5], "lectur": 0, "left": [1, 2, 3, 4, 5], "leftarrow": 2, "leq": 2, "less": 3, "lesson": [2, 3, 4, 5], "let": [0, 1, 5], "level": 1, "leverag": 1, "like": [0, 1, 2, 3, 4], "likelihood": 2, "limit": 1, "line": 1, "linear": 5, "ll": [0, 1, 3, 4], "load": 1, "load_default": 1, "log": [2, 5], "log_prob": [2, 5], "log\u03c0": 5, "log\u03c0\u03b8": 2, "long": [0, 1, 2, 3, 4], "loop": 3, "loss": [2, 3, 4, 5], "love": 1, "m": [2, 5], "machin": [0, 1], "mai": 1, "maintain": 1, "make": [0, 1, 3], "mani": [1, 2, 3, 4], "map": [1, 5], "markov": 1, "materi": [0, 6], "math": [0, 1], "mathemat": [1, 5], "max": [3, 4], "max_norm": 3, "maxa": 3, "maxim": [1, 2, 3, 5], "maximum": [3, 4], "mdp": 1, "meal": 1, "mean": [1, 2, 3, 4, 5], "measur": 3, "memori": 1, "memoryless": 1, "menu": 1, "meter": 1, "method": [0, 1, 2, 3, 5], "metric": 1, "might": 1, "million": 1, "mimick": [0, 1], "mini_batch": 3, "mini_batch_s": 3, "minim": [2, 5], "mirror": 1, "misbehav": 1, "mistak": 0, "model": [1, 2, 3, 4, 5], "modifi": 1, "modul": 5, "moment": 1, "mont": [2, 3], "month": 1, "more": [0, 1, 2, 3, 5], "most": 1, "move": 2, "mse": 5, "mseloss": [3, 4], "much": [1, 2, 3, 4, 5], "multipl": 5, "mutat": 1, "nabla_": 2, "natur": [0, 1], "navig": [0, 1], "nearbi": 1, "need": [0, 1, 2], "neg": [0, 1, 2], "neighborhood": 1, "network": [1, 5], "neural": [1, 5], "new": [0, 1, 2, 3, 4], "new_stat": [2, 3, 4, 5], "new_state_tensor": 4, "next": [2, 3, 4, 5], "next_act": [3, 4], "next_q_valu": [3, 4], "nn": [3, 4, 5], "note": 2, "now": [1, 2], "np": [2, 3, 4], "number": 3, "numer": 1, "numpi": [2, 3, 4], "object": 1, "observ": [2, 3, 4, 5], "obstacl": [0, 1], "obtain": [2, 3], "occur": 2, "off": [0, 3], "offer": 1, "often": [3, 4], "onc": [2, 5], "one": [0, 1, 2], "ones": 0, "onli": [0, 1, 3], "onlin": 3, "onpolicy_reset": 2, "onward": [2, 3], "open": 1, "oper": 1, "opposit": 2, "opt": 1, "optim": [0, 1, 2, 3, 4, 5], "option": [0, 1, 5], "order": 2, "other": [0, 1, 3], "otherwis": [3, 4], "our": [1, 2], "outcom": 1, "outlin": 2, "output": 1, "output_s": [3, 4, 5], "over": [0, 1, 2, 3, 4, 5], "p": [1, 2], "pair": [3, 4], "parallel": 5, "paramet": [0, 2, 3], "parameter": 2, "part": [1, 3], "particular": [1, 5], "past": [0, 1, 3], "path": 1, "penal": [1, 5], "penalti": [0, 1], "perfectli": 1, "perform": [0, 1, 2, 4], "period": 3, "pgcar": 2, "pgrace": 2, "pi_": 2, "pil": 1, "pixel": 1, "plan": 1, "plu": 3, "png": 1, "point": 2, "polici": [0, 3, 4, 5], "policy_loss": 2, "popular": [3, 5], "posit": [0, 1], "possibl": [0, 1, 2, 3, 4], "potenti": 1, "pow": 5, "ppo": 1, "practic": 2, "predict": [1, 5], "prefer": 0, "present": 1, "prevent": [1, 3], "previou": [1, 3], "previous": 2, "primari": 5, "primarili": 1, "principl": 0, "print": 1, "prob": [2, 5], "probabl": [0, 1, 2, 3, 4, 5], "problem": [0, 1], "process": 1, "produc": 2, "program": 0, "progress": 0, "project": 0, "promot": 1, "properti": 1, "provid": [1, 3, 5], "proxim": 1, "puppi": 1, "python": 0, "q": [0, 1, 5], "qcar": 3, "qlearn": 1, "qrace": 3, "qualiti": [1, 5], "quantifi": 5, "quickli": [0, 1], "quit": 1, "r": [2, 3, 4, 5], "r_": [1, 2], "r_1": 2, "r_2": 2, "r_k": 2, "r_t": 2, "race": [0, 1], "radian": 1, "randint": [3, 4], "random": [3, 4], "randomli": [2, 3], "rang": [1, 2, 3, 4, 5], "rapidli": 3, "rate": [2, 3, 4], "rather": 4, "ratio": 2, "raw": 3, "re": 1, "read": 1, "readi": 0, "real": [0, 1], "receiv": [0, 1, 2, 3, 4, 5], "recurr": 1, "recurs": 3, "reduc": [1, 5], "refer": 1, "refin": [3, 5], "reflect": 2, "reinforc": [0, 3, 4, 5], "relat": [2, 4], "relationship": 3, "relev": 1, "reli": [1, 3, 4], "reliabl": [1, 5], "relu": 5, "repeat": [2, 3, 4, 5], "repeatedli": 2, "replay_memori": 3, "repres": [0, 1, 2, 3], "represent": 1, "requir": 1, "reset_episod": 5, "resiz": 1, "respond": 1, "respons": [3, 5], "restart": 1, "restaur": 1, "result": 1, "retain": 1, "return": [1, 2, 3, 4, 5], "reus": 3, "revers": 2, "reward": [0, 2, 3, 5], "right": [1, 2, 3, 4, 5], "rl": [0, 1, 2, 6], "row": 1, "rule": [2, 3, 4], "s_": [1, 2], "s_0": 2, "s_1": 2, "s_t": [1, 2], "safe": 0, "sai": 1, "same": [1, 3], "sampl": [2, 3, 5], "sarsa": [0, 1, 5], "sarsacar": 4, "sarsarac": 4, "satisfi": 1, "saw": 3, "scold": 1, "scratch": 0, "see": [0, 1], "seem": 1, "seen": 1, "select": [0, 1, 2, 3, 5], "select_act": 5, "self": [2, 3, 4, 5], "sensor": 1, "sequenc": 2, "sequenti": 5, "set": [2, 3, 4], "sever": 1, "shape": 1, "share": [1, 5], "shift": [1, 3], "short": 1, "should": [2, 3, 4], "show": 3, "side": 1, "significantli": 1, "similar": [1, 4], "similarli": [1, 4], "simpl": 1, "simpler": [3, 4], "simpli": 2, "simplif": 1, "simplifi": 1, "simul": [0, 1], "sin": 1, "singl": 5, "sit": 1, "size": 1, "skill": 1, "skip": 0, "slow": [1, 2, 3, 4, 5], "slowli": 3, "so": [0, 2], "softmax": 5, "sole": 1, "solut": 0, "solv": 0, "someth": 1, "sophist": 0, "specif": 1, "specifi": 1, "speed": [0, 1, 2, 3, 4, 5], "spot": 1, "squar": 5, "squeez": [3, 4, 5], "ss": [3, 5], "st": [2, 3], "stabil": [3, 5], "stabl": [3, 5], "stack": [2, 5], "stai": 0, "start": [1, 2, 3, 4, 5], "state": [0, 2, 3, 5], "state_tensor": 4, "steepest": 2, "step": [0, 2, 3, 4, 5], "stick": 1, "still": 0, "stochast": 1, "store": [2, 3], "straightforward": 1, "strateg": 1, "strategi": [0, 1, 3, 4], "streamlin": 1, "strength": 5, "studi": [0, 1], "suboptim": 1, "subsequ": 3, "subset": 1, "succe": 1, "success": 1, "suffici": [1, 3], "sum": 2, "sum_": 2, "summar": 1, "summari": 2, "super": 5, "superior": 1, "supervis": 1, "synchron": 5, "system": 1, "t": [1, 2, 3], "tabl": [1, 3, 4], "take": [0, 1, 2, 3, 4, 5], "taken": [1, 2, 3, 4], "target": [4, 5], "target_model": 3, "target_q_valu": [3, 4], "tast": 1, "tau": 2, "taught": 6, "td": [3, 4, 5], "technic": 5, "techniqu": [0, 1, 3, 5], "tell": 5, "tensor": [2, 3, 4, 5], "term": [0, 1, 3, 4, 5], "test": [0, 1], "text": 1, "text_posit": 1, "than": [2, 3, 4], "thei": [0, 1, 2, 3], "them": [0, 3], "theoret": 0, "theori": 0, "theta": 2, "thi": [0, 1, 2, 3, 4, 5], "think": 1, "those": [1, 2], "through": [0, 1], "throughout": 2, "ti": 1, "tight": 1, "time": [0, 1, 2, 3, 4, 5], "tip": 0, "tonight": 1, "too": 3, "torch": [2, 3, 4, 5], "total": [1, 2, 3, 5], "total_reward": 1, "toward": 3, "track": [0, 1], "trade": 1, "tradeoff": 4, "tradit": 0, "train": 0, "train_everi": 5, "training_rac": [2, 3, 4, 5], "trajectori": [1, 2], "translat": 0, "travel": 1, "treat": 1, "trendi": 1, "trial": [0, 1], "try": [1, 3], "tune": 1, "turn": 1, "two": [1, 5], "type": 1, "typic": 3, "u": [1, 5], "ultim": 0, "uncertainti": 1, "under": [2, 4, 5], "underli": 0, "understand": [0, 1, 5], "undesir": 1, "unlik": [0, 1, 3, 4, 5], "unsqueez": [2, 3, 4, 5], "until": [2, 3, 4], "up": [1, 2, 3, 4, 5], "updat": [0, 1, 2, 3, 4, 5], "update_replay_memori": 3, "update_target_network": 3, "upon": 5, "us": [0, 1, 2, 3, 4], "usual": 2, "util": [1, 3], "v": [0, 3, 4, 5], "v_\u03c0": 1, "valu": [0, 1, 5], "valuabl": [1, 2], "vanilla": 5, "varianc": [3, 5], "variou": 1, "veloc": 1, "version": 5, "video": [1, 2, 3, 4, 5], "visit": 1, "wa": 5, "wai": [1, 2], "wait": [3, 4], "wall": 1, "want": 1, "watch": 0, "we": [0, 1, 2, 3, 4, 5], "weigh": 2, "weight": 3, "welcom": [1, 6], "well": 1, "were": [3, 5], "when": 3, "where": [0, 1, 2, 3, 5], "whether": 1, "which": [1, 2, 3, 4, 5], "while": [0, 1, 2, 3, 4, 5], "white": 1, "width": 1, "win": 0, "within": 0, "without": [0, 1, 2, 3, 4, 5], "wonder": 1, "word": 3, "work": [0, 1, 2, 3, 4, 5], "world": [0, 1], "wors": 5, "would": [1, 3], "write": 1, "x": [1, 3, 5], "y": 1, "yield": 1, "you": 1, "your": [0, 1], "zero": [3, 4], "zero_grad": [2, 3, 4, 5], "zip": [2, 3], "\u03b1": [3, 4], "\u03b3": [1, 3, 4, 5], "\u03b3a": 3, "\u03b3max": 3, "\u03b3maxa": 3, "\u03b3q": 4, "\u03b3r_": 1, "\u03b3v": 5, "\u03b8": 2, "\u03c0": [1, 5], "\u03c0\u03b8": [2, 5], "\u03c4": 2, "\u03f5": [3, 4], "\u03f51": 4, "\u03f5\u03f5": [3, 4]}, "titles": ["Welcome to RAICE!", "Reinforcement Learning", "Policy gradients (Reinforce)", "Q-Learning", "SARSA (State-Action-Reward-State-Action)", "A2C (Advantage Actor-Critic)", "&lt;no title&gt;"], "titleterms": {"": 1, "On": 1, "The": [1, 2, 3, 4, 5], "Will": 0, "a2c": 5, "action": [1, 4], "actor": 5, "actual": [2, 3, 4, 5], "advantag": 5, "agent": 1, "algorithm": [1, 5], "an": 1, "code": [2, 3, 4, 5], "compon": 5, "cours": 0, "critic": 5, "deep": 3, "differ": [3, 4], "environ": 1, "epsilon": [3, 4], "exampl": 1, "exploit": 1, "explor": [1, 3, 4], "function": [2, 3, 4, 5], "gradient": 2, "greedi": [3, 4], "i": 1, "kei": 5, "learn": [0, 1, 3, 4], "memori": 3, "network": 3, "object": 2, "off": 1, "overview": 5, "polici": [1, 2], "prerequisit": 0, "process": [2, 3, 4, 5], "q": [3, 4], "r": 1, "raic": [0, 1], "reinforc": [1, 2], "replai": 3, "reward": [1, 4], "sarsa": 4, "scenario": 1, "state": [1, 4], "structur": 0, "target": 3, "tempor": [3, 4], "train": [1, 2, 3, 4, 5], "us": 5, "v": 1, "valu": [3, 4], "welcom": 0, "what": [0, 1], "why": 5, "you": 0}})