Search.setIndex({"alltitles": {"A2C (Advantage Actor-Critic)": [[5, null]], "A2C Algorithm": [[5, "a2c-algorithm"]], "Actor-Critic Overview": [[5, "actor-critic-overview"]], "Actual Training": [[7, "actual-training"]], "Actual training": [[2, "actual-training"], [3, "actual-training"], [4, "actual-training"], [5, "actual-training"]], "Advantage Function": [[5, "advantage-function"]], "Algorithms": [[1, "algorithms"]], "Coding A2C": [[5, "coding-a2c"]], "Coding Deep Q-Network": [[3, "coding-deep-q-network"]], "Coding Policy Gradients": [[2, "coding-policy-gradients"]], "Coding SARSA": [[4, "coding-sarsa"]], "Course Structure:": [[0, "course-structure"]], "Epsilon-Greedy Exploration": [[3, "epsilon-greedy-exploration"]], "Epsilon-Greedy Exploration in SARSA": [[4, "epsilon-greedy-exploration-in-sarsa"]], "Exploration vs. Exploitation": [[1, "exploration-vs-exploitation"]], "Highlights": [[2, "highlights"]], "Key Components of A2C": [[5, "key-components-of-a2c"]], "Key Concepts in NEAT": [[7, "key-concepts-in-neat"]], "NEAT (NeuroEvolution of Augmenting Topologies)": [[7, null]], "On-Policy vs. Off-Policy Learning": [[1, "on-policy-vs-off-policy-learning"]], "Overview of NEAT": [[7, "overview-of-neat"]], "PPO": [[6, null]], "Policy gradients (Reinforce)": [[2, null]], "Prerequisites:": [[0, "prerequisites"]], "Q-Learning": [[3, null]], "RAICE": [[8, null]], "RAICE: An Example Scenario": [[1, "raice-an-example-scenario"]], "Reinforcement Learning": [[1, null]], "Replay Memory": [[3, "replay-memory"]], "SARSA (State-Action-Reward-State-Action)": [[4, null]], "Target network": [[3, "target-network"]], "Temporal Difference Learning in SARSA": [[4, "temporal-difference-learning-in-sarsa"]], "Temporal difference learning": [[3, "temporal-difference-learning"]], "The A2C Process": [[5, "the-a2c-process"]], "The Actions a": [[1, "the-actions-a"]], "The Advantage Function": [[5, "the-advantage-function"]], "The Agent": [[1, "the-agent"]], "The Environment": [[1, "the-environment"]], "The NEAT Process": [[7, "the-neat-process"]], "The Policy Gradient Process": [[2, "the-policy-gradient-process"]], "The Q-Learning Process": [[3, "the-q-learning-process"]], "The Q-Value Function": [[3, "the-q-value-function"]], "The Q-Value Function in SARSA": [[4, "the-q-value-function-in-sarsa"]], "The Reward r": [[1, "the-reward-r"]], "The SARSA Process": [[4, "the-sarsa-process"]], "The State s": [[1, "the-state-s"]], "The objective function": [[2, "the-objective-function"]], "Training the Agent": [[1, "training-the-agent"]], "Understanding Fitness in NEAT": [[7, "understanding-fitness-in-neat"]], "Using the NEAT-Python Library": [[7, "using-the-neat-python-library"]], "Welcome to RAICE!": [[0, null]], "What You Will Learn:": [[0, "what-you-will-learn"]], "What is Reinforcement Learning?": [[1, "what-is-reinforcement-learning"]], "Why Use Advantage?": [[5, "why-use-advantage"]]}, "docnames": ["00_introduction", "01_reinforcement_learning", "02_policy_gradients", "03_dqn", "04_sarsa", "05_a2c", "06_ppo", "07_neat", "intro"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["00_introduction.ipynb", "01_reinforcement_learning.ipynb", "02_policy_gradients.ipynb", "03_dqn.ipynb", "04_sarsa.ipynb", "05_a2c.ipynb", "06_ppo.ipynb", "07_neat.ipynb", "intro.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 2, 3, 4, 5, 7], "0": [1, 2, 3, 4, 5, 7], "000": 3, "02": 2, "03": 2, "05": 2, "06": 2, "1": [1, 2, 3, 4, 5, 7], "10": [1, 2, 3, 4, 5], "120": 1, "15": 1, "2": [1, 2, 3, 4, 5, 7], "20": [2, 7], "200": 1, "22": 2, "2r_": 1, "3": [1, 2], "30": [1, 7], "360": 1, "40": 7, "400": 1, "45": 1, "5": 1, "50": 2, "500": 1, "6": [2, 3, 4, 5], "7": 1, "700": 1, "8": 1, "90": 1, "A": [0, 1, 2, 5], "And": 7, "As": [1, 7], "At": 5, "But": [0, 1], "By": [1, 2, 3], "For": [0, 1, 2, 3, 4, 7], "IT": 6, "If": [1, 2, 4, 7], "In": [0, 1, 2, 3, 4, 5, 7], "It": [1, 3, 5, 7], "No": 7, "Not": 7, "OF": [3, 5, 7], "ON": 6, "Or": 2, "THE": [3, 5, 7], "Thats": 1, "The": 0, "There": [0, 1], "These": [1, 2, 7, 8], "To": [1, 2, 3, 7], "With": [3, 4], "__init__": [2, 3, 4, 5], "_\u03c4": 2, "_\u03c4p": 2, "a2car": 5, "a2crac": 5, "a_": 1, "a_0": 2, "a_1": 2, "a_t": [1, 2], "aa": [3, 4, 5], "abl": 0, "about": [1, 7], "ac": 5, "acceler": 5, "accompani": 0, "accord": [2, 4, 5], "account": 2, "accumul": 2, "achiev": [0, 1], "act_epsilon_greedi": [3, 4], "action": [0, 2, 3, 5], "action_train": [2, 3, 4, 5, 7], "acton": 7, "actor": 1, "actor_loss": 5, "actorcrit": 5, "actual": 1, "ad": 3, "adapt": 0, "add": 7, "address": 3, "adjust": [0, 1, 2, 3, 5], "advanc": 7, "advantag": 7, "after": [2, 3, 4, 5, 7], "again": 4, "agent": [0, 2, 3, 4, 5], "aggress": 0, "ai": [0, 1], "aim": [1, 3, 4], "algorithm": [0, 2, 3, 4, 7], "align": 7, "aliv": 7, "all": [1, 2, 3, 4], "allow": [0, 1, 2, 3, 5, 7], "along": 2, "alpha": 2, "alreadi": [0, 1], "also": [0, 1, 2, 4], "altern": 1, "alwai": 1, "among": 1, "an": [0, 2, 3, 4, 5, 7], "angl": [1, 2, 3, 4, 5], "ani": [1, 3], "anoth": 1, "append": [2, 5], "appli": [0, 2], "applic": 0, "approach": [1, 3, 7], "approxim": 5, "ar": [0, 1, 2, 3, 4, 5, 7, 8], "arbitrarili": [3, 4], "architectur": 7, "argmax": [3, 4], "arrai": [2, 3, 4], "artifici": [0, 7], "ascent": 2, "aspect": 1, "asphalt": 1, "assign": [1, 7], "associ": 1, "assum": 3, "asynchron": 5, "atmospher": 1, "augment": 1, "automat": 7, "averag": 5, "avoid": [0, 1], "back": 7, "background": 1, "backpropag": [4, 7], "backward": [2, 3, 4, 5], "bahrain": 1, "bahrain2": 1, "balanc": [0, 1, 3, 4, 7], "ball": 1, "base": [0, 1, 2, 3, 4, 5, 7], "baselin": 5, "basic": [0, 2], "becaus": 1, "becom": 3, "befor": [1, 7], "behavior": [0, 1], "behind": 5, "being": [1, 7], "bellman": 3, "below": 3, "best": [0, 1, 3, 4, 7], "better": [0, 1, 5], "between": [0, 1, 3, 4, 5, 7], "black": 1, "blue": 1, "bonu": 5, "bootstrap": [3, 5], "both": [0, 1, 3, 5, 7], "boundari": 0, "break": [0, 3, 7], "buffer": 3, "c1": 5, "c1critic": 5, "c2": 5, "c2entropi": 5, "calcul": [4, 5, 7], "can": [0, 1, 2, 3, 7], "captur": [1, 5], "car": [0, 1, 2, 3, 4, 5, 7], "carlo": [2, 3], "carri": 1, "case": [0, 1, 2], "categor": [2, 5], "cdot": 2, "center": 1, "central": 3, "certain": [1, 7], "chanc": 7, "chang": 3, "chapter": [0, 3], "check": 7, "choic": 1, "choos": [1, 3, 4, 5], "chosen": 5, "class": [2, 3, 4, 5, 7], "clear": [0, 1], "clip_grad_norm_": 3, "close": 4, "co": 1, "code": 0, "collect": [2, 3], "collid": 0, "color": 1, "column": 1, "combin": [0, 1, 3, 5, 7], "come": 1, "comfort": 0, "common": 3, "compar": [1, 5], "compet": 0, "competit": 0, "complet": [0, 2], "complex": [0, 1, 7], "complexif": 7, "complic": 1, "compon": 3, "comput": [1, 2, 3, 4, 5], "concept": [0, 1, 5], "conceptu": 0, "confid": 5, "configur": 1, "connect": 7, "consecut": 3, "consid": 1, "consist": [1, 5], "context": [1, 7], "continu": 7, "contrast": 3, "contribut": [2, 5], "control": [3, 4, 5], "converg": [2, 3, 4], "convers": 1, "copi": 3, "core": [0, 5], "corner": 1, "cornerston": 1, "correl": 3, "correspond": 1, "cort\u00e9": 8, "could": [1, 3, 5], "counter": 7, "cours": [1, 8], "cover": [0, 1], "crash": 1, "creat": [1, 7], "create_model": [2, 3, 4], "criterion": 7, "critic": 1, "critic_loss": 5, "critic_weight": 5, "crossov": [1, 7], "crucial": 1, "cumul": [1, 3, 4, 5], "current": [1, 2, 3, 4, 5], "current_q_valu": [3, 4], "current_st": [2, 3, 4, 5], "curv": 2, "d": 1, "data": 1, "debug": 0, "decai": [1, 3, 4], "decid": 5, "decis": [0, 1, 2], "decreas": 1, "deep": 0, "def": [1, 2, 3, 4, 5, 7], "default": 1, "defin": [1, 2, 5, 7], "degre": 1, "delv": [0, 1], "denot": 3, "depend": 1, "deriv": [2, 3], "descent": 2, "design": 1, "desir": 1, "detach": 5, "detail": [0, 3, 5], "detect": 1, "determin": [1, 3, 7], "determinist": 1, "develop": 1, "devic": [2, 3, 4, 5], "differ": [0, 1, 5, 7], "dilemma": 1, "dim": 5, "dine": 1, "dinner": 1, "direct": [1, 2, 7], "directli": [0, 1, 2, 3, 5], "discount": [1, 2, 3, 4, 5], "discount_factor": [2, 3, 4, 5], "discourag": 1, "discov": 1, "discuss": [1, 2], "displai": 1, "distanc": 1, "distant": 2, "distribut": [1, 2, 5], "dive": [0, 3], "divers": [3, 7], "divid": 7, "do": 2, "document": 7, "doe": 3, "doesn": [1, 3, 7], "done": [2, 3, 4, 5], "dot": 2, "down": [0, 1, 2, 3, 4, 5], "dqn": [1, 3], "draw": 1, "drive": [0, 1, 3, 4], "driver": 1, "dtype": [2, 3, 4], "dure": [1, 2, 3, 5, 7], "dynam": [0, 1], "e": [0, 1, 3, 5], "e_\u03c0": 1, "each": [0, 1, 2, 3, 4, 5, 7], "earli": [3, 5], "earlier": 2, "easi": 7, "effect": [1, 3, 7], "effici": [0, 1, 3], "either": [1, 7], "element": 1, "elif": [2, 3, 4, 5], "elimin": 7, "els": [2, 3, 4, 5], "embark": 0, "emploi": 1, "en": 7, "enabl": [1, 7], "encod": 7, "encompass": 1, "encount": 2, "encourag": [1, 5], "end": [0, 2, 3, 4], "enjoy": 1, "ensur": 3, "entir": [1, 2], "entropi": 5, "entropy_loss": 5, "entropy_weight": 5, "enumer": 7, "environ": [0, 2, 3, 5, 7], "episod": [2, 3, 4, 5], "episode_reward": [2, 3, 4, 5], "epsilon_decai": [3, 4], "equal": 3, "equat": [3, 4], "equip": 1, "equival": 2, "errat": 3, "error": [0, 1, 3, 4, 5], "especi": 3, "essenti": [1, 7], "estim": [1, 2, 3, 5], "evalu": [1, 5, 7], "even": 3, "everi": [1, 2, 3], "evolut": 1, "evolutionari": [0, 7], "evolv": [0, 1, 7], "exactli": 1, "exampl": 0, "excit": [0, 1], "execut": [2, 3, 4, 5], "exist": 1, "expect": [1, 2, 3, 4, 5], "experi": [0, 1, 2, 3], "explain": [0, 2], "explan": 0, "exploit": [0, 3, 4], "explor": [0, 5, 7], "exploratori": 3, "express": [2, 3], "e\u03c4": 2, "f": 1, "f1": [0, 1], "face": 1, "fact": 2, "factor": [1, 2, 3, 4, 5], "fals": [2, 3, 4, 5], "familiar": [0, 1], "far": 3, "favor": 5, "favorit": 1, "featur": 7, "feed": 1, "feedback": [0, 1, 3, 5], "fernando": 8, "fetch": 1, "fill": 1, "final": 1, "find": [0, 1, 7], "fine": 1, "finish": 3, "finnish": 4, "first": [0, 2], "fit": 1, "fittest": 7, "five": 1, "fix": 3, "flexibl": [3, 7], "float": 2, "float32": [2, 3, 4], "floattensor": 5, "fluctuat": 3, "focu": [0, 1, 5], "focus": [0, 1], "follow": [0, 1, 2, 3, 4, 7], "font": 1, "food": 1, "form": [0, 3], "formal": [1, 2, 3], "formul": [1, 2], "formula": 3, "forward": [2, 5], "foundat": 1, "four": 1, "free": 1, "frequent": 3, "fresh": 1, "from": [0, 1, 2, 3, 4, 5, 7], "from_numpi": 2, "front": 1, "frozen": 3, "full": 2, "function": [0, 1], "fundament": 0, "futur": [1, 2, 3, 4, 5], "future_return": 2, "g": [0, 1, 2], "g_t": 2, "gain": 0, "game": [0, 1], "game_map": 7, "gamma": 2, "gather": [1, 3, 4], "gene": 7, "gener": [0, 1, 2, 7], "genet": [0, 1, 7], "genom": 7, "get": [0, 4, 5, 7], "get_data": [2, 3, 4, 5], "get_q": [3, 4], "get_reward": 7, "give": 2, "given": [1, 2, 3, 5, 7], "go": [0, 7], "goal": [0, 1, 2, 5], "good": [0, 1, 5], "gradient": [0, 3, 5], "gradual": [3, 7], "grasp": 0, "greater": 1, "greatli": 1, "green": 1, "grid": 1, "gridworld": 0, "gt": 3, "guarante": 1, "guid": [0, 1], "ha": [1, 4], "hand": [0, 1], "happen": 1, "have": [1, 2, 4, 7], "heavili": 2, "help": [0, 1, 2, 3, 5, 7], "here": [2, 3, 4, 5], "hidden_s": 5, "high": [1, 3], "higher": [2, 5], "highest": [3, 4], "highli": 5, "histor": [1, 7], "hold": 1, "horizon": 2, "how": [0, 1, 2, 3, 4, 5, 7], "howev": [1, 3, 4], "http": 7, "human": 1, "hybrid": 1, "hyperparamet": 5, "i": [0, 2, 3, 4, 5, 7], "idea": [0, 3, 5], "imag": 1, "imagedraw": 1, "imagefont": 1, "imagin": 1, "immedi": [1, 2, 3, 4], "implement": [0, 5, 7], "import": [1, 2, 3, 4, 5], "improv": [0, 1, 2, 3, 5], "includ": [1, 7], "incorpor": [1, 5], "increas": [1, 2, 7], "increment": 3, "independ": 1, "indic": [1, 5], "indirectli": 3, "individu": 7, "inform": [1, 3], "initi": [2, 3, 4, 5, 7], "innov": 7, "input_s": 5, "insert": [2, 3, 5, 7], "instabl": 3, "instal": 7, "instead": [1, 3, 5], "instruct": 7, "int": [1, 3, 4], "intellig": 0, "interact": [0, 1, 2, 3, 5], "intili": 2, "intiliaz": [3, 4], "intric": 1, "introduc": 3, "intuit": 0, "involv": [1, 2, 5], "io": 7, "ipython": 1, "irrelev": 1, "is_al": 7, "item": [2, 3, 4, 5], "iter": [1, 3], "its": [1, 2, 3, 5, 7], "itself": 1, "j": 2, "journei": 0, "just": [1, 5], "k": 2, "keep": 1, "kei": [0, 1, 3, 4], "know": 1, "knowledg": [0, 3], "known": [0, 1, 2, 3, 5, 7], "label": 1, "lack": 1, "lap": [0, 2], "later": 2, "latest": 7, "lead": [1, 2, 3, 5], "learn": [2, 5, 7], "lectur": 0, "left": [1, 2, 3, 4, 5], "leftarrow": 2, "leq": 2, "less": 3, "lesson": [2, 3, 4, 5, 7], "let": [0, 1, 5], "level": 1, "leverag": 1, "like": [0, 1, 2, 3, 4, 7], "likelihood": 2, "limit": 1, "line": 1, "linear": 5, "ll": [0, 1, 3, 4, 7], "load": 1, "load_default": 1, "log": [2, 5], "log_prob": [2, 5], "log\u03c0": 5, "log\u03c0\u03b8": 2, "long": [0, 1, 2, 3, 4], "loop": [3, 7], "loss": [2, 3, 4, 5], "love": 1, "m": [2, 5], "machin": [0, 1], "mai": 1, "main": 7, "maintain": [1, 7], "make": [0, 1, 2, 3], "mani": [1, 2, 3, 4, 7], "manipul": 7, "map": [1, 5], "mark": 7, "markov": 1, "materi": [0, 8], "math": [0, 1], "mathemat": [1, 5], "max": [3, 4], "max_a": 3, "max_norm": 3, "maxa": [], "maxim": [1, 2, 3, 5], "maximum": [3, 4], "mdp": 1, "meal": 1, "mean": [1, 2, 3, 4, 5], "meaning": 7, "measur": [3, 7], "memori": 1, "memoryless": 1, "menu": 1, "meter": 1, "method": [0, 1, 2, 3, 5, 7], "metric": 1, "might": 1, "million": 1, "mimick": [0, 1], "mini_batch": 3, "mini_batch_s": 3, "minim": [2, 5, 7], "mirror": 1, "misbehav": 1, "mistak": 0, "model": [1, 2, 3, 4, 5], "modifi": [1, 7], "modul": 5, "moment": 1, "mont": [2, 3], "month": 1, "more": [0, 1, 2, 3, 5, 7], "most": 1, "move": 2, "mse": 5, "mseloss": [3, 4], "much": [1, 2, 3, 4, 5], "multipl": 5, "mutat": [1, 7], "nabla_": 2, "natur": [0, 1], "navig": [0, 1], "nearbi": 1, "neatrac": 7, "need": [0, 1, 2], "neg": [0, 1, 2], "neighborhood": 1, "network": [1, 5, 7], "neural": [1, 5, 7], "new": [0, 1, 2, 3, 4, 7], "new_stat": [2, 3, 4, 5], "new_state_tensor": 4, "newli": 7, "next": [2, 3, 4, 5], "next_act": [3, 4], "next_q_valu": [3, 4], "nn": [3, 4, 5], "node": 7, "note": 2, "now": [1, 2], "np": [2, 3, 4], "number": 3, "numer": 1, "numpi": [2, 3, 4], "object": 1, "observ": [2, 3, 4, 5], "obstacl": [0, 1], "obtain": [2, 3], "occur": 2, "off": [0, 3], "offer": 1, "offspr": 7, "often": [3, 4], "old": 7, "onc": [2, 5], "one": [0, 1, 2], "ones": [0, 7], "onli": [0, 1, 3], "onlin": 3, "onpolicy_reset": 2, "onward": [2, 3], "open": 1, "oper": [1, 7], "opposit": 2, "opt": 1, "optim": [0, 1, 2, 3, 4, 5, 7], "option": [0, 1, 5], "order": 2, "other": [0, 1, 3], "otherwis": [3, 4], "our": [1, 2, 7], "outcom": 1, "outlin": 2, "output": 1, "output_s": [3, 4, 5], "over": [0, 1, 2, 3, 4, 5, 7], "p": [1, 2], "pair": [3, 4], "parallel": 5, "paramet": [0, 2, 3], "parameter": 2, "parent": 7, "part": [1, 3], "particular": [1, 5, 7], "particularli": 7, "past": [0, 1, 3], "path": 1, "penal": [1, 5], "penalti": [0, 1], "perfectli": 1, "perform": [0, 1, 2, 4, 7], "period": 3, "pgcar": 2, "pgrace": 2, "pi_": 2, "pil": 1, "pixel": 1, "plan": 1, "plu": 3, "png": 1, "point": 2, "polici": [0, 3, 4, 5], "policy_loss": 2, "popul": 7, "popular": [3, 5], "posit": [0, 1], "possibl": [0, 1, 2, 3, 4], "potenti": 1, "pow": 5, "power": 7, "ppo": 1, "practic": 2, "predict": [1, 5], "prefer": 0, "present": 1, "preserv": 7, "prevent": [1, 3, 7], "previou": [1, 3, 7], "previous": 2, "primari": 5, "primarili": 1, "principl": [0, 7], "print": 1, "prob": [2, 5], "probabl": [0, 1, 2, 3, 4, 5], "problem": [0, 1, 7], "process": 1, "produc": 2, "program": 0, "progress": 0, "project": 0, "promot": 1, "properti": 1, "protect": 7, "provid": [1, 3, 5, 7], "proxim": 1, "puppi": 1, "purpos": 7, "python": 0, "q": [0, 1, 5], "qcar": 3, "qlearn": 1, "qrace": 3, "qualiti": [1, 5], "quantifi": 5, "quickli": [0, 1], "quit": 1, "r": [2, 3, 4, 5], "r_": [1, 2], "r_1": 2, "r_2": 2, "r_k": 2, "r_t": 2, "race": [0, 1, 7], "radian": 1, "randint": [3, 4], "random": [3, 4, 7], "randomli": [2, 3], "rang": [1, 2, 3, 4, 5], "rapidli": 3, "rate": [2, 3, 4], "rather": 4, "ratio": 2, "raw": 3, "re": 1, "read": 1, "readi": 0, "readthedoc": 7, "real": [0, 1], "receiv": [0, 1, 2, 3, 4, 5], "recurr": 1, "recurs": 3, "red": 1, "reduc": [1, 5], "refer": 1, "refin": [3, 5], "reflect": 2, "reinforc": [0, 3, 4, 5, 7], "relat": [2, 4], "relationship": 3, "relev": 1, "reli": [1, 3, 4], "reliabl": [1, 5], "relu": 5, "remov": 7, "repeat": [2, 3, 4, 5, 7], "repeatedli": 2, "replac": 7, "replay_memori": 3, "repres": [0, 1, 2, 3, 7], "represent": 1, "reproduc": 7, "reproduct": 7, "requir": [1, 7], "reset_episod": 5, "resiz": 1, "respond": 1, "respons": [3, 5], "restart": 1, "restaur": 1, "result": 1, "retain": 1, "return": [1, 2, 3, 4, 5], "reus": 3, "revers": 2, "reward": [0, 2, 3, 5, 7], "right": [1, 2, 3, 4, 5], "rl": [0, 1, 2, 8], "row": 1, "rule": [2, 3, 4], "run": [2, 7], "s_": [1, 2], "s_0": 2, "s_1": 2, "s_t": [1, 2], "safe": 0, "sai": 1, "same": [1, 3, 7], "sampl": [2, 3, 5], "sarsa": [0, 1, 5], "sarsacar": 4, "sarsarac": 4, "satisfi": 1, "saw": 3, "scalabl": 7, "scale": 7, "scenario": 7, "scheme": 7, "scold": 1, "scratch": 0, "second": 7, "see": [0, 1], "seem": 1, "seen": 1, "select": [0, 1, 2, 3, 5, 7], "select_act": 5, "self": [2, 3, 4, 5, 7], "sensor": 1, "sequenc": 2, "sequenti": 5, "serv": 7, "set": [2, 3, 4], "sever": 1, "shape": 1, "share": [1, 5], "shift": [1, 3], "short": 1, "should": [2, 3, 4], "show": 3, "side": 1, "significantli": 1, "similar": [1, 4, 7], "similarli": [1, 4], "simpl": [1, 7], "simpler": [3, 4], "simpli": 2, "simplif": 1, "simplifi": 1, "simul": [0, 1], "sin": 1, "sinc": 7, "singl": [5, 7], "sit": 1, "size": 1, "skill": 1, "skip": 0, "slow": [1, 2, 3, 4, 5], "slowli": 3, "so": [0, 2], "softmax": 5, "sole": 1, "solut": [0, 7], "solv": 0, "someth": 1, "sophist": 0, "space": 7, "speci": 7, "speciat": 7, "specif": 1, "specifi": 1, "speed": [0, 1, 2, 3, 4, 5], "spot": 1, "squar": 5, "squeez": [3, 4, 5], "ss": [3, 5], "st": [2, 3], "stabil": [3, 5], "stabl": [3, 5], "stack": [2, 5], "stai": 0, "start": [1, 2, 3, 4, 5, 7], "state": [0, 2, 3, 5], "state_tensor": 4, "steepest": 2, "step": [0, 2, 3, 4, 5, 7], "stick": 1, "still": [0, 7], "still_al": 7, "stochast": 1, "stop": 7, "store": [2, 3], "straightforward": 1, "strateg": 1, "strategi": [0, 1, 3, 4, 7], "streamlin": 1, "strength": 5, "structur": 7, "studi": [0, 1], "suboptim": 1, "subsequ": 3, "subset": 1, "succe": 1, "success": 1, "suffici": [1, 3], "sum": 2, "sum_": 2, "summar": 1, "summari": 2, "super": 5, "superior": 1, "supervis": 1, "surviv": 7, "synchron": 5, "system": 1, "t": [1, 2, 3, 7], "tabl": [1, 3, 4], "take": [0, 1, 2, 3, 4, 5, 7], "taken": [1, 2, 3, 4], "target": [4, 5], "target_model": 3, "target_q_valu": [3, 4], "task": 7, "tast": 1, "tau": 2, "taught": 8, "td": [3, 4, 5], "technic": 5, "techniqu": [0, 1, 3, 5], "tell": 5, "tensor": [2, 3, 4, 5], "term": [0, 1, 3, 4, 5], "test": [0, 1], "text": 1, "text_posit": 1, "than": [2, 3, 4], "thei": [0, 1, 2, 3, 7], "them": [0, 3], "theoret": 0, "theori": 0, "theta": 2, "thi": [0, 1, 2, 3, 4, 5, 7], "think": 1, "those": [1, 2], "through": [0, 1, 2, 7], "throughout": 2, "ti": 1, "tight": 1, "time": [0, 1, 2, 3, 4, 5, 7], "tip": 0, "tonight": 1, "too": 3, "topolog": 7, "torch": [2, 3, 4, 5], "total": [1, 2, 3, 5], "total_reward": 1, "toward": 3, "track": [0, 1], "trade": 1, "tradeoff": 4, "tradit": [0, 7], "train": 0, "train_everi": 5, "training_rac": [2, 3, 4, 5, 7], "trajectori": [1, 2], "translat": 0, "travel": 1, "treat": 1, "trendi": 1, "trial": [0, 1], "true": 7, "try": [1, 3], "tune": 1, "turn": 1, "two": [1, 5, 7], "type": 1, "typic": 3, "u": [1, 5], "ultim": 0, "uncertainti": 1, "under": [2, 4, 5], "underli": 0, "understand": [0, 1, 5], "undesir": 1, "uniqu": 7, "unknown": 7, "unlik": [0, 1, 3, 4, 5, 7], "unsqueez": [2, 3, 4, 5], "until": [2, 3, 4], "up": [1, 2, 3, 4, 5], "updat": [0, 1, 2, 3, 4, 5, 7], "update_replay_memori": 3, "update_target_network": 3, "upon": 5, "us": [0, 1, 2, 3, 4], "usual": 2, "util": [1, 3], "v": [0, 3, 4, 5], "v_\u03c0": 1, "valu": [0, 1, 5], "valuabl": [1, 2], "vanilla": 5, "varianc": [3, 5], "variou": 1, "veloc": 1, "version": 5, "video": [1, 3, 5, 7], "visit": 1, "wa": 5, "wai": [1, 2], "wait": [3, 4], "wall": 1, "want": 1, "watch": 0, "we": [0, 1, 2, 3, 4, 5, 7], "weigh": 2, "weight": [3, 7], "welcom": [1, 8], "well": [1, 7], "were": [3, 5], "when": [3, 7], "where": [0, 1, 2, 3, 5, 7], "whether": 1, "which": [1, 2, 3, 4, 5, 7], "while": [0, 1, 2, 3, 4, 5, 7], "white": 1, "width": 1, "win": 0, "within": 0, "without": [0, 1, 2, 3, 4, 5], "wonder": 1, "word": 3, "work": [0, 1, 2, 3, 4, 5, 6], "world": [0, 1], "wors": 5, "would": [1, 3], "write": 1, "x": [1, 3, 5], "y": 1, "ye": 7, "yield": 1, "you": [1, 7], "your": [0, 1], "zero": [3, 4], "zero_grad": [2, 3, 4, 5], "zip": [2, 3], "\u03b1": [3, 4], "\u03b3": [1, 3, 4, 5], "\u03b3a": 3, "\u03b3max": 3, "\u03b3maxa": 3, "\u03b3q": 4, "\u03b3r_": 1, "\u03b3v": 5, "\u03b8": 2, "\u03c0": [1, 5], "\u03c0\u03b8": [2, 5], "\u03c4": 2, "\u03f5": [3, 4], "\u03f51": 4, "\u03f5\u03f5": [3, 4]}, "titles": ["Welcome to RAICE!", "Reinforcement Learning", "Policy gradients (Reinforce)", "Q-Learning", "SARSA (State-Action-Reward-State-Action)", "A2C (Advantage Actor-Critic)", "PPO", "NEAT (NeuroEvolution of Augmenting Topologies)", "RAICE"], "titleterms": {"": 1, "IT": [], "ON": [], "On": 1, "The": [1, 2, 3, 4, 5, 7], "Will": 0, "a2c": 5, "action": [1, 4], "actor": 5, "actual": [2, 3, 4, 5, 7], "advantag": 5, "agent": 1, "algorithm": [1, 5], "an": 1, "augment": 7, "code": [2, 3, 4, 5], "compon": 5, "concept": 7, "cours": 0, "critic": 5, "deep": 3, "differ": [3, 4], "environ": 1, "epsilon": [3, 4], "exampl": 1, "exploit": 1, "explor": [1, 3, 4], "fit": 7, "function": [2, 3, 4, 5], "gradient": 2, "greedi": [3, 4], "highlight": 2, "i": 1, "kei": [5, 7], "learn": [0, 1, 3, 4], "librari": 7, "memori": 3, "neat": 7, "network": 3, "neuroevolut": 7, "object": 2, "off": 1, "overview": [5, 7], "polici": [1, 2], "ppo": 6, "prerequisit": 0, "process": [2, 3, 4, 5, 7], "python": 7, "q": [3, 4], "r": 1, "raic": [0, 1, 8], "reinforc": [1, 2], "replai": 3, "reward": [1, 4], "sarsa": 4, "scenario": 1, "state": [1, 4], "structur": 0, "target": 3, "tempor": [3, 4], "topologi": 7, "train": [1, 2, 3, 4, 5, 7], "understand": 7, "us": [5, 7], "v": 1, "valu": [3, 4], "welcom": 0, "what": [0, 1], "why": 5, "work": [], "you": 0}})