Search.setIndex({"alltitles": {"A2C (Advantage Actor-Critic)": [[6, null]], "A2C Algorithm": [[6, "a2c-algorithm"]], "Actor-Critic Overview": [[6, "actor-critic-overview"]], "Actual training": [[3, "actual-training"], [4, "actual-training"], [5, "actual-training"], [6, "actual-training"]], "Advantage Function": [[6, "advantage-function"]], "Algorithms": [[2, "algorithms"]], "Coding A2C": [[6, "coding-a2c"]], "Coding Deep Q-Network": [[4, "coding-deep-q-network"]], "Coding Policy Gradients": [[3, "coding-policy-gradients"]], "Coding SARSA": [[5, "coding-sarsa"]], "Course Structure:": [[0, "course-structure"], [1, "course-structure"]], "Epsilon-Greedy Exploration": [[4, "epsilon-greedy-exploration"]], "Epsilon-Greedy Exploration in SARSA": [[5, "epsilon-greedy-exploration-in-sarsa"]], "Exploration vs. Exploitation": [[2, "exploration-vs-exploitation"]], "Key Components of A2C": [[6, "key-components-of-a2c"]], "On-Policy vs. Off-Policy Learning": [[2, "on-policy-vs-off-policy-learning"]], "Policy gradients (Reinforce)": [[3, null]], "Prerequisites:": [[0, "prerequisites"], [1, "prerequisites"]], "Q-Learning": [[4, null]], "RAICE": [[7, null]], "RAICE: An Example Scenario": [[2, "raice-an-example-scenario"]], "Reinforcement Learning": [[2, null]], "Replay Memory": [[4, "replay-memory"]], "SARSA (State-Action-Reward-State-Action)": [[5, null]], "Target network": [[4, "target-network"]], "Temporal Difference Learning in SARSA": [[5, "temporal-difference-learning-in-sarsa"]], "Temporal difference learning": [[4, "temporal-difference-learning"]], "The A2C Process": [[6, "the-a2c-process"]], "The Actions a": [[2, "the-actions-a"]], "The Advantage Function": [[6, "the-advantage-function"]], "The Agent": [[2, "the-agent"]], "The Environment": [[2, "the-environment"]], "The Policy Gradient Process": [[3, "the-policy-gradient-process"]], "The Q-Learning Process": [[4, "the-q-learning-process"]], "The Q-Value Function": [[4, "the-q-value-function"]], "The Q-Value Function in SARSA": [[5, "the-q-value-function-in-sarsa"]], "The Reward r": [[2, "the-reward-r"]], "The SARSA Process": [[5, "the-sarsa-process"]], "The State s": [[2, "the-state-s"]], "The objective function": [[3, "the-objective-function"]], "Training the Agent": [[2, "training-the-agent"]], "Welcome to RAICE!": [[0, null], [1, null]], "What You Will Learn:": [[0, "what-you-will-learn"], [1, "what-you-will-learn"]], "What is Reinforcement Learning?": [[2, "what-is-reinforcement-learning"]], "Why Use Advantage?": [[6, "why-use-advantage"]]}, "docnames": ["00_Introduction", "00_introduction", "01_reinforcement_learning", "02_policy_gradients", "03_dqn", "04_sarsa", "05_a2c", "intro"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["00_Introduction.ipynb", "00_introduction.ipynb", "01_reinforcement_learning.ipynb", "02_policy_gradients.ipynb", "03_dqn.ipynb", "04_sarsa.ipynb", "05_a2c.ipynb", "intro.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 4, 5, 6], "0": [2, 3, 4, 5, 6], "000": 4, "1": [2, 3, 4, 5, 6], "10": [2, 3, 4, 5, 6], "120": 2, "15": 2, "2": [2, 3, 4, 5, 6], "200": 2, "2r_": 2, "3": [2, 3], "30": 2, "360": 2, "400": 2, "45": 2, "5": 2, "50": 3, "500": 2, "6": [3, 4, 5, 6], "7": 2, "700": 2, "8": 2, "90": 2, "A": [0, 1, 2, 3, 6], "As": 2, "At": 6, "But": [0, 1, 2], "By": [2, 3, 4], "For": [0, 1, 2, 3, 4, 5], "If": [2, 3, 5], "In": [0, 1, 2, 3, 4, 5, 6], "It": [2, 4, 6], "OF": [3, 4, 5, 6], "Or": 3, "THE": [3, 4, 5, 6], "Thats": 2, "The": [0, 1], "There": [0, 1, 2], "These": [2, 3, 7], "To": [2, 3, 4], "With": [4, 5], "__init__": [3, 4, 5, 6], "_\u03c4": 3, "_\u03c4p": 3, "a2car": 6, "a2crac": 6, "a_": 2, "a_0": 3, "a_1": 3, "a_t": [2, 3], "aa": [4, 5, 6], "abl": [0, 1], "about": 2, "ac": 6, "acceler": 6, "accompani": [0, 1], "accord": [3, 5, 6], "account": 3, "accumul": 3, "achiev": [0, 1, 2], "act_epsilon_greedi": [4, 5], "action": [0, 1, 3, 4, 6], "action_train": [3, 4, 5, 6], "actor": 2, "actor_loss": 6, "actorcrit": 6, "actual": 2, "ad": 4, "adapt": [0, 1], "address": 4, "adjust": [0, 1, 2, 3, 4, 6], "after": [3, 4, 5, 6], "again": 5, "agent": [0, 1, 3, 4, 5, 6], "aggress": [0, 1], "ai": [0, 1, 2], "aim": [2, 4, 5], "algorithm": [0, 1, 3, 4, 5], "all": [2, 3, 4, 5], "allow": [0, 1, 2, 3, 4, 6], "along": 3, "alpha": 3, "alreadi": [0, 1, 2], "also": [0, 1, 2, 3, 5], "altern": 2, "alwai": 2, "among": 2, "an": [0, 1, 3, 4, 5, 6], "angl": [2, 3, 4, 5, 6], "ani": [2, 4], "anoth": 2, "append": [3, 6], "appli": [0, 1, 3], "applic": [0, 1], "approach": [2, 4], "approxim": 6, "ar": [0, 1, 2, 3, 4, 5, 6, 7], "arbitrarili": [4, 5], "argmax": [4, 5], "arrai": [3, 4, 5], "artifici": [0, 1], "ascent": 3, "aspect": 2, "asphalt": 2, "assign": 2, "associ": 2, "assum": 4, "asynchron": 6, "atmospher": 2, "augment": 2, "averag": 6, "avoid": [0, 1, 2], "background": 2, "backpropag": 5, "backward": [3, 4, 5, 6], "bahrain": 2, "bahrain2": 2, "balanc": [0, 1, 2, 4, 5], "ball": 2, "base": [0, 1, 2, 3, 4, 5, 6], "baselin": 6, "basic": [0, 1, 3], "becaus": 2, "becom": 4, "befor": 2, "behavior": [0, 1, 2], "behind": 6, "being": 2, "bellman": 4, "below": 4, "best": [0, 1, 2, 4, 5], "better": [0, 1, 2, 6], "between": [0, 1, 2, 4, 5, 6], "black": 2, "blue": 2, "bonu": 6, "bootstrap": [4, 6], "both": [0, 1, 2, 4, 6], "boundari": [0, 1], "break": [0, 1, 4], "buffer": 4, "c1": 6, "c1critic": 6, "c2": 6, "c2entropi": 6, "calcul": [5, 6], "can": [0, 1, 2, 3, 4], "captur": [2, 6], "car": [0, 1, 2, 3, 4, 5, 6], "carlo": [3, 4], "carri": 2, "case": [0, 1, 2, 3], "categor": [3, 6], "cdot": 3, "center": 2, "central": 4, "certain": 2, "chang": 4, "chapter": [0, 1, 4], "choic": 2, "choos": [2, 4, 5, 6], "chosen": 6, "class": [3, 4, 5, 6], "clear": [0, 1, 2], "clip_grad_norm_": 4, "close": 5, "co": 2, "code": [0, 1], "collect": [3, 4], "collid": [0, 1], "color": 2, "column": 2, "combin": [0, 1, 2, 4, 6], "come": 2, "comfort": [0, 1], "common": 4, "compar": [2, 6], "compet": [0, 1], "competit": [0, 1], "complet": [0, 1, 3], "complex": [0, 1, 2], "complic": 2, "compon": 4, "comput": [2, 3, 4, 5, 6], "concept": [0, 1, 2, 6], "conceptu": [0, 1], "confid": 6, "configur": 2, "consecut": 4, "consid": 2, "consist": [2, 6], "context": 2, "contrast": 4, "contribut": [3, 6], "control": [4, 5, 6], "converg": [3, 4, 5], "convers": 2, "copi": 4, "core": [0, 1, 6], "corner": 2, "cornerston": 2, "correl": 4, "correspond": 2, "cort\u00e9": 7, "could": [2, 4, 6], "cours": [2, 7], "cover": [0, 1, 2], "crash": 2, "creat": 2, "create_model": [3, 4, 5], "critic": 2, "critic_loss": 6, "critic_weight": 6, "crossov": 2, "crucial": 2, "cumul": [2, 4, 5, 6], "current": [2, 3, 4, 5, 6], "current_q_valu": [4, 5], "current_st": [3, 4, 5, 6], "d": 2, "data": 2, "debug": [0, 1], "decai": [2, 4, 5], "decid": 6, "decis": [0, 1, 2, 3], "decreas": 2, "deep": [0, 1], "def": [2, 3, 4, 5, 6], "default": 2, "defin": [2, 3, 6], "degre": 2, "delv": [0, 1, 2], "denot": 4, "depend": 2, "deriv": [3, 4], "descent": 3, "design": 2, "desir": 2, "detach": 6, "detail": [0, 1, 4, 6], "detect": 2, "determin": [2, 4], "determinist": 2, "develop": 2, "devic": [3, 4, 5, 6], "differ": [0, 1, 2, 6], "dilemma": 2, "dim": 6, "dine": 2, "dinner": 2, "direct": [2, 3], "directli": [0, 1, 2, 3, 4, 6], "discount": [2, 3, 4, 5, 6], "discount_factor": [3, 4, 5, 6], "discourag": 2, "discov": 2, "discuss": [2, 3], "displai": 2, "distanc": 2, "distant": 3, "distribut": [2, 3, 6], "dive": [0, 1, 4], "divers": 4, "do": 3, "doe": 4, "doesn": [2, 4], "done": [3, 4, 5, 6], "dot": 3, "down": [0, 1, 2, 3, 4, 5, 6], "dqn": [2, 4], "draw": 2, "drive": [0, 1, 2, 4, 5], "driver": 2, "dtype": [3, 4, 5], "dure": [2, 3, 4, 6], "dynam": [0, 1, 2], "e": [0, 1, 2, 4, 6], "e_\u03c0": 2, "each": [0, 1, 2, 3, 4, 5, 6], "earli": [4, 6], "earlier": 3, "effect": [2, 4], "effici": [0, 1, 2, 4], "either": 2, "element": 2, "elif": [3, 4, 5, 6], "els": [3, 4, 5, 6], "embark": [0, 1], "emploi": 2, "enabl": 2, "encompass": 2, "encount": 3, "encourag": [2, 6], "end": [0, 1, 3, 4, 5], "enjoy": 2, "ensur": 4, "entir": [2, 3], "entropi": 6, "entropy_loss": 6, "entropy_weight": 6, "environ": [0, 1, 3, 4, 6], "episod": [3, 4, 5, 6], "episode_reward": [3, 4, 5, 6], "epsilon_decai": [4, 5], "equal": 4, "equat": [4, 5], "equip": 2, "equival": 3, "errat": 4, "error": [0, 1, 2, 4, 5, 6], "especi": 4, "essenti": 2, "estim": [2, 3, 4, 6], "evalu": [2, 6], "even": 4, "everi": [2, 3, 4], "evolut": 2, "evolutionari": [0, 1], "evolv": [0, 1, 2], "exactli": 2, "exampl": [0, 1], "excit": [0, 1, 2], "execut": [3, 4, 5, 6], "exist": 2, "expect": [2, 3, 4, 5, 6], "experi": [0, 1, 2, 3, 4], "explain": [0, 1, 3], "explan": [0, 1], "exploit": [0, 1, 4, 5], "explor": [0, 1, 6], "exploratori": 4, "express": [3, 4], "e\u03c4": 3, "f": 2, "f1": [0, 1, 2], "face": 2, "fact": 3, "factor": [2, 3, 4, 5, 6], "fals": [3, 4, 5, 6], "familiar": [0, 1, 2], "far": 4, "favor": 6, "favorit": 2, "feed": 2, "feedback": [0, 1, 2, 4, 6], "fernando": 7, "fetch": 2, "fill": 2, "final": 2, "find": [0, 1, 2], "fine": 2, "finish": 4, "finnish": 5, "first": [0, 1, 3], "fit": 2, "five": 2, "fix": 4, "flexibl": 4, "float": 3, "float32": [3, 4, 5], "floattensor": 6, "fluctuat": 4, "focu": [0, 1, 2, 6], "focus": [0, 1, 2], "follow": [0, 1, 2, 3, 4, 5], "font": 2, "food": 2, "form": [0, 1, 4], "formal": [2, 3, 4], "formul": [2, 3], "formula": 4, "forward": [3, 6], "foundat": 2, "four": 2, "free": 2, "frequent": 4, "fresh": 2, "from": [0, 1, 2, 3, 4, 5, 6], "from_numpi": 3, "front": 2, "frozen": 4, "function": [0, 1, 2], "fundament": [0, 1], "futur": [2, 3, 4, 5, 6], "future_return": 3, "g": [0, 1, 2, 3], "g_t": 3, "gain": [0, 1], "game": [0, 1, 2], "gamma": 3, "gather": [2, 4, 5], "gener": [0, 1, 2, 3], "genet": [0, 1, 2], "get": [0, 1, 5, 6], "get_data": [3, 4, 5, 6], "get_q": [4, 5], "give": 3, "given": [2, 3, 4, 6], "go": [0, 1], "goal": [0, 1, 2, 3, 6], "good": [0, 1, 2, 6], "gradient": [0, 1, 4, 6], "gradual": 4, "grasp": [0, 1], "greater": 2, "greatli": 2, "green": 2, "grid": 2, "gridworld": [0, 1], "gt": 4, "guarante": 2, "guid": [0, 1, 2], "ha": [2, 5], "hand": [0, 1, 2], "happen": 2, "have": [2, 3, 5], "heavili": 3, "help": [0, 1, 2, 3, 4, 6], "here": [3, 4, 5, 6], "hidden_s": 6, "high": [2, 4], "higher": [3, 6], "highest": [4, 5], "highli": 6, "histor": 2, "hold": 2, "horizon": 3, "how": [0, 1, 2, 3, 4, 5, 6], "howev": [2, 4, 5], "human": 2, "hybrid": 2, "hyperparamet": 6, "i": [0, 1, 3, 4, 5, 6], "idea": [0, 1, 4, 6], "imag": 2, "imagedraw": 2, "imagefont": 2, "imagin": 2, "immedi": [2, 3, 4, 5], "implement": [0, 1, 6], "import": [2, 3, 4, 5, 6], "improv": [0, 1, 2, 3, 4, 6], "includ": 2, "incorpor": [2, 6], "increas": [2, 3], "increment": 4, "independ": 2, "indic": [2, 6], "indirectli": 4, "inform": [2, 4], "initi": [3, 4, 5, 6], "input_s": 6, "insert": [3, 4, 5, 6], "instabl": 4, "instead": [2, 4, 6], "int": [2, 4, 5], "intellig": [0, 1], "interact": [0, 1, 2, 3, 4, 6], "intili": 3, "intiliaz": [4, 5], "intric": 2, "introduc": 4, "intuit": [0, 1], "involv": [2, 3, 6], "ipython": 2, "irrelev": 2, "item": [3, 4, 5, 6], "iter": [2, 4], "its": [2, 3, 4, 6], "itself": 2, "j": 3, "journei": [0, 1], "just": [2, 6], "k": 3, "keep": 2, "kei": [0, 1, 2, 4, 5], "know": 2, "knowledg": [0, 1, 4], "known": [0, 1, 2, 3, 4, 6], "label": 2, "lack": 2, "lap": [0, 1], "later": 3, "lead": [2, 3, 4, 6], "learn": [3, 6], "lectur": [0, 1], "left": [2, 3, 4, 5, 6], "leftarrow": 3, "leq": 3, "less": 4, "lesson": [3, 4, 5, 6], "let": [0, 1, 2, 6], "level": 2, "leverag": 2, "like": [0, 1, 2, 3, 4, 5], "likelihood": 3, "limit": 2, "line": 2, "linear": 6, "ll": [0, 1, 2, 4, 5], "load": 2, "load_default": 2, "log": [3, 6], "log_prob": [3, 6], "log\u03c0": 6, "log\u03c0\u03b8": 3, "long": [0, 1, 2, 3, 4, 5], "loop": 4, "loss": [3, 4, 5, 6], "love": 2, "m": [3, 6], "machin": [0, 1, 2], "mai": 2, "maintain": 2, "make": [0, 1, 2, 4], "mani": [2, 3, 4, 5], "map": [2, 6], "markov": 2, "materi": [0, 1, 7], "math": [0, 1, 2], "mathemat": [2, 6], "max": [4, 5], "max_norm": 4, "maxa": 4, "maxim": [2, 3, 4, 6], "maximum": [4, 5], "mdp": 2, "meal": 2, "mean": [2, 3, 4, 5, 6], "measur": 4, "memori": 2, "memoryless": 2, "menu": 2, "meter": 2, "method": [0, 1, 2, 3, 4, 6], "metric": 2, "might": 2, "million": 2, "mimick": [0, 1, 2], "mini_batch": 4, "mini_batch_s": 4, "minim": [3, 6], "mirror": 2, "misbehav": 2, "mistak": [0, 1], "model": [2, 3, 4, 5, 6], "modifi": 2, "modul": 6, "moment": 2, "mont": [3, 4], "month": 2, "more": [0, 1, 2, 3, 4, 6], "most": 2, "move": 3, "mse": 6, "mseloss": [4, 5], "much": [2, 3, 4, 5, 6], "multipl": 6, "mutat": 2, "nabla_": 3, "natur": [0, 1, 2], "navig": [0, 1, 2], "nearbi": 2, "need": [0, 1, 2, 3], "neg": [0, 1, 2, 3], "neighborhood": 2, "network": [2, 6], "neural": [2, 6], "new": [0, 1, 2, 3, 4, 5], "new_stat": [3, 4, 5, 6], "new_state_tensor": 5, "next": [3, 4, 5, 6], "next_act": [4, 5], "next_q_valu": [4, 5], "nn": [4, 5, 6], "note": 3, "now": [2, 3], "np": [3, 4, 5], "number": 4, "numer": 2, "numpi": [3, 4, 5], "object": 2, "observ": [3, 4, 5, 6], "obstacl": [0, 1, 2], "obtain": [3, 4], "occur": 3, "off": [0, 1, 4], "offer": 2, "often": [4, 5], "onc": [3, 6], "one": [0, 1, 2, 3], "ones": [0, 1], "onli": [0, 1, 2, 4], "onlin": 4, "onpolicy_reset": 3, "onward": [3, 4], "open": 2, "oper": 2, "opposit": 3, "opt": 2, "optim": [0, 1, 2, 3, 4, 5, 6], "option": [0, 1, 2, 6], "order": 3, "other": [0, 1, 2, 4], "otherwis": [4, 5], "our": [2, 3], "outcom": 2, "outlin": 3, "output": 2, "output_s": [4, 5, 6], "over": [0, 1, 2, 3, 4, 5, 6], "p": [2, 3], "pair": [4, 5], "parallel": 6, "paramet": [0, 1, 3, 4], "parameter": 3, "part": [2, 4], "particular": [2, 6], "past": [0, 1, 2, 4], "path": 2, "penal": [2, 6], "penalti": [0, 1, 2], "perfectli": 2, "perform": [0, 1, 2, 3, 5], "period": 4, "pgcar": 3, "pgrace": 3, "pi_": 3, "pil": 2, "pixel": 2, "plan": 2, "plu": 4, "png": 2, "point": 3, "polici": [0, 1, 4, 5, 6], "policy_loss": 3, "popular": [4, 6], "posit": [0, 1, 2], "possibl": [0, 1, 2, 3, 4, 5], "potenti": 2, "pow": 6, "ppo": 2, "practic": 3, "predict": [2, 6], "prefer": [0, 1], "present": 2, "prevent": [2, 4], "previou": [2, 4], "previous": 3, "primari": 6, "primarili": 2, "principl": [0, 1], "print": 2, "prob": [3, 6], "probabl": [0, 1, 2, 3, 4, 5, 6], "problem": [0, 1, 2], "process": 2, "produc": 3, "program": [0, 1], "progress": [0, 1], "project": [0, 1], "promot": 2, "properti": 2, "provid": [2, 4, 6], "proxim": 2, "puppi": 2, "python": [0, 1], "q": [0, 1, 2, 6], "qcar": 4, "qlearn": 2, "qrace": 4, "qualiti": [2, 6], "quantifi": 6, "quickli": [0, 1, 2], "quit": 2, "r": [3, 4, 5, 6], "r_": [2, 3], "r_1": 3, "r_2": 3, "r_k": 3, "r_t": 3, "race": [0, 1, 2], "radian": 2, "randint": [4, 5], "random": [4, 5], "randomli": [3, 4], "rang": [2, 3, 4, 5, 6], "rapidli": 4, "rate": [3, 4, 5], "rather": 5, "ratio": 3, "raw": 4, "re": 2, "read": 2, "readi": [0, 1], "real": [0, 1, 2], "receiv": [0, 1, 2, 3, 4, 5, 6], "recurr": 2, "recurs": 4, "reduc": [2, 6], "refer": 2, "refin": [4, 6], "reflect": 3, "reinforc": [0, 1, 4, 5, 6], "relat": [3, 5], "relationship": 4, "relev": 2, "reli": [2, 4, 5], "reliabl": [2, 6], "relu": 6, "repeat": [3, 4, 5, 6], "repeatedli": 3, "replay_memori": 4, "repres": [0, 1, 2, 3, 4], "represent": 2, "requir": 2, "reset_episod": 6, "resiz": 2, "respond": 2, "respons": [4, 6], "restart": 2, "restaur": 2, "result": 2, "retain": 2, "return": [2, 3, 4, 5, 6], "reus": 4, "revers": 3, "reward": [0, 1, 3, 4, 6], "right": [2, 3, 4, 5, 6], "rl": [0, 1, 2, 3, 7], "row": 2, "rule": [3, 4, 5], "s_": [2, 3], "s_0": 3, "s_1": 3, "s_t": [2, 3], "safe": [0, 1], "sai": 2, "same": [2, 4], "sampl": [3, 4, 6], "sarsa": [0, 1, 2, 6], "sarsacar": 5, "sarsarac": 5, "satisfi": 2, "saw": 4, "scold": 2, "scratch": [0, 1], "see": [0, 1, 2], "seem": 2, "seen": 2, "select": [0, 1, 2, 3, 4, 6], "select_act": 6, "self": [3, 4, 5, 6], "sensor": 2, "sequenc": 3, "sequenti": 6, "set": [3, 4, 5], "sever": 2, "shape": 2, "share": [2, 6], "shift": [2, 4], "short": 2, "should": [3, 4, 5], "show": 4, "side": 2, "significantli": 2, "similar": [2, 5], "similarli": [2, 5], "simpl": 2, "simpler": [4, 5], "simpli": 3, "simplif": 2, "simplifi": 2, "simul": [0, 1, 2], "sin": 2, "singl": 6, "sit": 2, "size": 2, "skill": 2, "skip": [0, 1], "slow": [2, 3, 4, 5, 6], "slowli": 4, "so": [0, 1, 3], "softmax": 6, "sole": 2, "solut": [0, 1], "solv": [0, 1], "someth": 2, "sophist": [0, 1], "specif": 2, "specifi": 2, "speed": [0, 1, 2, 3, 4, 5, 6], "spot": 2, "squar": 6, "squeez": [4, 5, 6], "ss": [4, 6], "st": [3, 4], "stabil": [4, 6], "stabl": [4, 6], "stack": [3, 6], "stai": [0, 1], "start": [2, 3, 4, 5, 6], "state": [0, 1, 3, 4, 6], "state_tensor": 5, "steepest": 3, "step": [0, 1, 3, 4, 5, 6], "stick": 2, "still": [0, 1], "stochast": 2, "store": [3, 4], "straightforward": 2, "strateg": 2, "strategi": [0, 1, 2, 4, 5], "streamlin": 2, "strength": 6, "studi": [0, 1, 2], "suboptim": 2, "subsequ": 4, "subset": 2, "succe": 2, "success": 2, "suffici": [2, 4], "sum": 3, "sum_": 3, "summar": 2, "summari": 3, "super": 6, "superior": 2, "supervis": 2, "synchron": 6, "system": 2, "t": [2, 3, 4], "tabl": [2, 4, 5], "take": [0, 1, 2, 3, 4, 5, 6], "taken": [2, 3, 4, 5], "target": [5, 6], "target_model": 4, "target_q_valu": [4, 5], "tast": 2, "tau": 3, "taught": 7, "td": [4, 5, 6], "technic": 6, "techniqu": [0, 1, 2, 4, 6], "tell": 6, "tensor": [3, 4, 5, 6], "term": [0, 1, 2, 4, 5, 6], "test": [0, 1, 2], "text": 2, "text_posit": 2, "than": [3, 4, 5], "thei": [0, 1, 2, 3, 4], "them": [0, 1, 4], "theoret": [0, 1], "theori": [0, 1], "theta": 3, "thi": [0, 1, 2, 3, 4, 5, 6], "think": 2, "those": [2, 3], "through": [0, 1, 2], "throughout": 3, "ti": 2, "tight": 2, "time": [0, 1, 2, 3, 4, 5, 6], "tip": [0, 1], "tonight": 2, "too": 4, "torch": [3, 4, 5, 6], "total": [2, 3, 4, 6], "total_reward": 2, "toward": 4, "track": [0, 1, 2], "trade": 2, "tradeoff": 5, "tradit": [0, 1], "train": [0, 1], "train_everi": 6, "training_rac": [3, 4, 5, 6], "trajectori": [2, 3], "translat": [0, 1], "travel": 2, "treat": 2, "trendi": 2, "trial": [0, 1, 2], "try": [2, 4], "tune": 2, "turn": 2, "two": [2, 6], "type": 2, "typic": 4, "u": [2, 6], "ultim": [0, 1], "uncertainti": 2, "under": [3, 5, 6], "underli": [0, 1], "understand": [0, 1, 2, 6], "undesir": 2, "unlik": [0, 1, 2, 4, 5, 6], "unsqueez": [3, 4, 5, 6], "until": [3, 4, 5], "up": [2, 3, 4, 5, 6], "updat": [0, 1, 2, 3, 4, 5, 6], "update_replay_memori": 4, "update_target_network": 4, "upon": 6, "us": [0, 1, 2, 3, 4, 5], "usual": 3, "util": [2, 4], "v": [0, 1, 4, 5, 6], "v_\u03c0": 2, "valu": [0, 1, 2, 6], "valuabl": [2, 3], "vanilla": 6, "varianc": [4, 6], "variou": 2, "veloc": 2, "version": 6, "video": [2, 3, 4, 5, 6], "visit": 2, "wa": 6, "wai": [2, 3], "wait": [4, 5], "wall": 2, "want": 2, "watch": [0, 1], "we": [0, 1, 2, 3, 4, 5, 6], "weigh": 3, "weight": 4, "welcom": [2, 7], "well": 2, "were": [4, 6], "when": 4, "where": [0, 1, 2, 3, 4, 6], "whether": 2, "which": [2, 3, 4, 5, 6], "while": [0, 1, 2, 3, 4, 5, 6], "white": 2, "width": 2, "win": [0, 1], "within": [0, 1], "without": [0, 1, 2, 3, 4, 5, 6], "wonder": 2, "word": 4, "work": [0, 1, 2, 3, 4, 5, 6], "world": [0, 1, 2], "wors": 6, "would": [2, 4], "write": 2, "x": [2, 4, 6], "y": 2, "yield": 2, "you": 2, "your": [0, 1, 2], "zero": [4, 5], "zero_grad": [3, 4, 5, 6], "zip": [3, 4], "\u03b1": [4, 5], "\u03b3": [2, 4, 5, 6], "\u03b3a": 4, "\u03b3max": 4, "\u03b3maxa": 4, "\u03b3q": 5, "\u03b3r_": 2, "\u03b3v": 6, "\u03b8": 3, "\u03c0": [2, 6], "\u03c0\u03b8": [3, 6], "\u03c4": 3, "\u03f5": [4, 5], "\u03f51": 5, "\u03f5\u03f5": [4, 5]}, "titles": ["Welcome to RAICE!", "Welcome to RAICE!", "Reinforcement Learning", "Policy gradients (Reinforce)", "Q-Learning", "SARSA (State-Action-Reward-State-Action)", "A2C (Advantage Actor-Critic)", "RAICE"], "titleterms": {"": 2, "On": 2, "The": [2, 3, 4, 5, 6], "Will": [0, 1], "a2c": 6, "action": [2, 5], "actor": 6, "actual": [3, 4, 5, 6], "advantag": 6, "agent": 2, "algorithm": [2, 6], "an": 2, "code": [3, 4, 5, 6], "compon": 6, "cours": [0, 1], "critic": 6, "deep": 4, "differ": [4, 5], "environ": 2, "epsilon": [4, 5], "exampl": 2, "exploit": 2, "explor": [2, 4, 5], "function": [3, 4, 5, 6], "gradient": 3, "greedi": [4, 5], "i": 2, "kei": 6, "learn": [0, 1, 2, 4, 5], "memori": 4, "network": 4, "object": 3, "off": 2, "overview": 6, "polici": [2, 3], "prerequisit": [0, 1], "process": [3, 4, 5, 6], "q": [4, 5], "r": 2, "raic": [0, 1, 2, 7], "reinforc": [2, 3], "replai": 4, "reward": [2, 5], "sarsa": 5, "scenario": 2, "state": [2, 5], "structur": [0, 1], "target": 4, "tempor": [4, 5], "train": [2, 3, 4, 5, 6], "us": 6, "v": 2, "valu": [4, 5], "welcom": [0, 1], "what": [0, 1, 2], "why": 6, "you": [0, 1]}})